version: '3.8'

services:
  lora-wizard:
    build:
      context: .
      args:
        - PUID=${PUID:-99}
        - PGID=${PGID:-100}
    ports:
      - "8000:8000"
    volumes:
      # Map specific data subdirectories to preserve built-in templates
      # User needs to ensure these host paths exist or are created by Unraid/Docker
      - /mnt/user/appdata/lora-wizard/datasets:/app/data/datasets
      - /mnt/user/appdata/lora-wizard/models:/app/data/models
      # Keep log mapping separate
      - /mnt/user/appdata/lora-wizard/logs:/app/logs
    environment:
      - PUID=${PUID:-99}
      - PGID=${PGID:-100}
      - HOST=0.0.0.0
      - PORT=8000
      - NVIDIA_VISIBLE_DEVICES=all
      - PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:512
      - CUDA_LAUNCH_BLOCKING=1
      # CUDA_HOME is usually set by the base image, remove unless needed
      # - CUDA_HOME=/usr/local/cuda
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [ gpu ]
    runtime: nvidia
    ipc: host
    ulimits:
      memlock: -1
      stack: 67108864
    shm_size: '16gb'
    healthcheck:
      # Check if the root path of the web UI is accessible
      test: [ "CMD", "curl", "-f", "http://localhost:8000/" ] # Adjust path if the root isn't the health endpoint
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s # Give time for app and models to potentially load

# Removed redundant top-level volume definition for 'models' as it's handled by binds
# volumes:
#   models:
#     driver: local
